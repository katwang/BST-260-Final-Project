---
title: 'BST 260 Final Project: Cleaning Physician Compare National Data File'
author: Eunice Yeh
output: html_document
---

# Purpose
1. explore the data and summarize key variables
2. clean/reduce data: decide which rows and columns to filter out

## 1. Exploratory Analysis
Import data from `.csv` file.
```{r}
dat <- read.csv("Physician_Compare_National_Downloadable_File.csv")
```

Quick look at the data structure.
```{r}
str(dat)
```

Load `tidyverse` package for data wrangling and plotting functions.
```{r}
library(tidyverse)
```

Check frequency of Medicare assignment acceptance.
```{r}
table(dat$Professional.accepts.Medicare.Assignment)
```

Look at the distribution of physician graduation year by physician credentials and by use of EHR.
```{r}
gradyr <- dat %>% filter(!is.na(Graduation.year)) %>% 
  group_by(Credential, Used.electronic.health.records) 

gradyr %>% 
  ggplot(aes(Graduation.year)) +
  geom_histogram(color = "black") +
  facet_grid(.~Used.electronic.health.records) +
  ggtitle("Distribution of Grduation Year by Use of EHR")

gradyr %>% filter(Used.electronic.health.records == 'Y') %>%
  ungroup() %>% 
  mutate(Credential = reorder(Credential, Graduation.year)) %>% 
  ggplot(aes(factor(Credential), Graduation.year)) +
  geom_boxplot() + 
  # scale_y_continuous(trans = "sqrt", breaks = seq(0, 100, 2)^2) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.25)) +
  xlab("Credential") +
  ylab("Graduation Year") +
  ggtitle("Dist of Grad Year by Credential among those who used EHR")

gradyr %>%
  ungroup() %>% 
  mutate(Credential = reorder(Credential, Graduation.year)) %>% 
  ggplot(aes(factor(Credential), Graduation.year)) +
  geom_boxplot() + 
  facet_grid(.~Used.electronic.health.records) +
  # scale_y_continuous(trans = "sqrt", breaks = seq(0, 100, 2)^2) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.25)) +
  xlab("Credential") +
  ylab("Graduation Year") +
  ggtitle("Dist of Grad Year by Credential")
```

Look at the distribution of physician graduation year by US States separately for those who used EHR and for those who have not indicated using EHR.
```{r}
# for those who used EHR
gradyr %>% ungroup() %>% filter(Used.electronic.health.records == 'Y') %>% 
  mutate(State = reorder(State, Graduation.year)) %>% 
  ggplot(aes(factor(State), Graduation.year)) +
  geom_boxplot() + 
  # facet_grid(.~Used.electronic.health.records) +
  # scale_y_continuous(trans = "sqrt", breaks = seq(0, 100, 2)^2) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.25)) +
  xlab("US State") +
  ylab("Graduation Year") +
  ggtitle("Dist of Grad Year by State among those who used EHR")

# for those who did not indicate having used EHR
gradyr %>% ungroup() %>% filter(Used.electronic.health.records != 'Y') %>% 
  mutate(State = reorder(State, Graduation.year)) %>% 
  ggplot(aes(factor(State), Graduation.year)) +
  geom_boxplot() + 
  # facet_grid(.~Used.electronic.health.records) +
  # scale_y_continuous(trans = "sqrt", breaks = seq(0, 100, 2)^2) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.25)) +
  xlab("US State") +
  ylab("Graduation Year") +
  ggtitle("Dist of Grad Year by State among those who have not indicated using EHR")
rm(gradyr) # removing after use to save space
```

Calculate the proportion of EHR use by State.
```{r}
EHR_bystate <- dat %>% 
  group_by(State) %>% 
  summarize(EHR_count = sum(Used.electronic.health.records == 'Y'), total = n(), 
            EHR_prop = EHR_count/total)
EHR_bystate
```

Plot the proportion of EHR use by State.
```{r}
EHR_bystate %>% mutate(State = reorder(State, EHR_prop)) %>% 
  ggplot(aes(factor(State), EHR_prop)) +
  geom_point() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.25)) +
  xlab("State") +
  ylab("Proportion of EHR Used") +
  ggtitle("Proportion of EHR Used by State")
rm(EHR_bystate)
```

Calculate the percentage of EHR use by Primary Specialty and by State. -- consider filterning out n() < 50 or 100?
```{r}
EHR_primspec_bystate <- dat %>% 
  filter(!is.na(Graduation.year)) %>% 
  group_by(State, Primary.specialty) %>% 
  summarize(EHR_count = sum(Used.electronic.health.records == 'Y'), total = n(), EHR_percent = EHR_count/total * 100) %>% 
  mutate(Primary.specialty = reorder(Primary.specialty, EHR_percent))
EHR_primspec_bystate
```

Plot the percentage of EHR use by Primary Specialty and by State.
```{r}
library(RColorBrewer)
EHR_primspec_bystate %>% filter(total > 100) %>% 
  ggplot(aes(Primary.specialty, State,  fill = EHR_percent)) +
  geom_tile(color = "grey50") +
  # scale_x_continuous(expand=c(0,0)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +
  scale_fill_gradientn(colors = brewer.pal(9, "YlGn")) +  
  theme(panel.grid = element_blank()) +
  ylab("US States") + 
  xlab("Primary Specialty") +
  ggtitle("Percentage of EHR Used by Primary Specialty and States")
rm(EHR_primspec_bystate)
```


## 2. Data Cleaning Decisions:

1. filter out states outside of the main 50 except for DC since there is not a lot of information in those states and the other data we want to merge with do not contain information on these states anyway.

```{r}
unique(dat$State)
data("state")
new_dat <- dat[dat$State %in% unique(state.abb) == "TRUE" | dat$State == "DC", ]
unique(new_dat$State)
```

2. keep only rows with `Professional.accepts.Medicare.Assignment = 'Y'` since we are only interested in practioners who have definitely accepted medicare assignments, and we need to merge with other data that only contain those serving Medicare.

```{r}
rm(dat) # removing previous data to save space and speed up run time
table(new_dat$Professional.accepts.Medicare.Assignment)
filtered_dat <- new_dat %>% filter(Professional.accepts.Medicare.Assignment == 'Y')
table(filtered_dat$Professional.accepts.Medicare.Assignment)
```

3. key variables are NPI, last and first name, gender, credential, medical school name, grad year, prim specialty, all sec specialties,  organization legal name, num of group practice members, city, state, zip code,  hospital affiliation CCNs and LBNs,  used EHR, reported qual measures.

```{r}
rm(new_dat)
# easier to exclude than to type out all the variables to include
select_dat <- filtered_dat %>% select(-PAC.ID, -Professional.Enrollment.ID, -Middle.Name, -Suffix, -Group.Practice.PAC.ID, -Line.1.Street.Address, -Line.2.Street.Address, -Marker.of.address.line.2.suppression, -Phone.Number, -Professional.accepts.Medicare.Assignment, -Committed.to.heart.health.through.the.Million.Hearts√Ç..initiative.)
str(select_dat)
```

4. merge in accurate city, state, latitude, longitude information by zip codes using the `zipcode` package.

```{r}
rm(filtered_dat)
# separate out the first five zip codes from the last four extension to match R zipcode data
zip_dat <- select_dat %>% mutate(zip = substr(as.character(Zip.Code), 1, 5), zip.ext = substr(as.character(Zip.Code), 6, 9))

# use R zipcode package and data
library(zipcode)
data("zipcode")
zip_dat <- zip_dat %>% left_join(zipcode,by='zip') 
zip_dat %>% select(NPI, Zip.Code, zip, zip.ext, City, State, city, state, latitude, longitude) %>% head(.,20)
```

Check mismatched state between our data and the zipcode data from R.
```{r}
rm(select_dat)

# look up top 10 records with state mismatches
zip_mismatch <- zip_dat %>% 
  mutate(State = as.character(State), state = as.character(state)) %>% 
  filter(State != state) %>% 
  select(NPI, zip, City, city, State, state) %>% 
  group_by(zip, City, State, city, state) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n)) %>% 
  head(5)
zip_mismatch
```

In order to not just blatantly throw away the mismatches, we will look at the top 5 most common mismatches on a case-by-case basis to try to salvage as many records as possible without searching too deeply in our dataset. Also, starting from the 6th most common mismatches, the number of records (n) were down to 58 or less, so they would have little effect on the dataset.

The results of searching up the top 10 mismatches on Google Maps:
- the zipcode 99362 spans across Walla Walla in both WA and OR, so it is likely that the practice is located on the WA side of the zipcode coverage. We will ignore the state mismatch from the zipcode package for this case.
- the zipcode 52761 does belong to Muscatine, IA, which is right on the border of IL. Again, the practice is most likely located on the IA side. Will ignore the state mismatch for this case as well.
- the zip code for Granger, IN was most likely mistyped. The correct zip code for Granger is 46530, which is very close to 43530. We will fix the zipcode for this particular case only.
- the zipcode 22401 does belong to Frederickburg, VA, and is not near the border of VA and MD at all. There is a "Frederick" city in MD, but none of its zipcodes look similar enough to 22401. No clear culprit, will have to let this one go. :(
- The zipcode for Hanover, MD is 21076, which was most likely mistyped as 20176. We will fix this particular case as well.

```{r}
rm(zipcode)

# leave out the 22401 Fredericksburg MD mismatch, fix the zip codes for Granger and Hanover.
zip_fix <- zip_mismatch %>% ungroup() %>% 
  filter(City != 'FREDERICKSBURG') %>% 
  mutate(zip = replace(zip, zip %in% c(43530, 20176), c(46530, 21076)))

mismatch_tokeep <- zip_dat %>% 
  select(-zip) %>% # we want to replace the original wrong zip codes with the fixed zip codes
  inner_join(zip_fix, by = c('City','State', 'city', 'state')) %>% 
  select(-city, -state) # the original city and state entered were correct

zip_dat <- zip_dat %>% 
  mutate(State = as.character(State), state = as.character(state)) %>% 
  filter(State == state) %>% # keeping only the matches
  bind_rows(mismatch_tokeep) # then add in the mismatches we wanted to keep or have fixed
```


5. keep only one record per physician (using NPI, first/last name, primary specialty and City, State and full zip code just to be extra precise)
```{r}
rm(zip_mismatch, zip_fix, mismatch_tokeep)

unique_dat <- zip_dat %>% distinct(NPI, Last.Name, First.Name, Primary.specialty, City, State, Zip.Code, .keep_all = TRUE)

# there are a few physicians who have multiple primary specialty (all other distinct columns stayed constant), although the most is having two specialities and there are only 17 of these cases. We will take out primary specialty as a unique factor.
unique_dat %>% group_by(NPI, City, State, Zip.Code) %>% summarize(n = n()) %>% arrange(desc(n)) %>% filter(n > 1)

unique_dat <- unique_dat %>% distinct(NPI, Last.Name, First.Name, City, State, Zip.Code, .keep_all = TRUE)
```
Note that the argument `.keep_all = TRUE` keeps all other variables not considered in the combination of variables that determine the uniqueness. If the combination is not distinct, the first row of values is kept, which is fine because we don't really care as much about the other variables. For example, the organization legal name and city may vary across multiple rows for the same physician who owns a private practice and renames or moves the practice around the area but still within the same state.

6. separate into two datasets by hospital affiliation vs. none

```{r}
# those with some kind of hospital affiliation
hosp <- unique_dat %>% filter(Hospital.affiliation.CCN.1 != "" | Hospital.affiliation.CCN.2 != "" | Hospital.affiliation.CCN.3 != "" | Hospital.affiliation.CCN.4 != "" | !is.na(Hospital.affiliation.CCN.5))
saveRDS(hosp, file="hosp.rds")

# those without any hospital affiliation
phys <- unique_dat %>% filter(Hospital.affiliation.CCN.1 == "" & Hospital.affiliation.CCN.2 == "" & Hospital.affiliation.CCN.3 == "" & Hospital.affiliation.CCN.4 == "" & is.na(Hospital.affiliation.CCN.5))
saveRDS(phys, file="phys.rds")
```


